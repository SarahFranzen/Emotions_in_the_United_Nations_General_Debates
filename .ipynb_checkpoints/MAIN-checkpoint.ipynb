{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f0994f-b5e3-45b5-a495-5c67b083d3d1",
   "metadata": {},
   "source": [
    "# Development of Emotion and Reasoning in the General Speeches of the United Nations: A text-based machine learning approach\n",
    "## MAIN - File\n",
    "\n",
    "### Description: \n",
    "It automatically runs all notebooks in the correct order, handles optional additional analyses, and can install required Python packages and download necessary resources. All outputs, including figures, tables, and results, are saved to their respective folders.\n",
    "\n",
    "It runs all notebooks in the correct order. The script installs required packages and downloads necessary resources. If you do not want this, set InstallPackages = False. It does not overwrite existing packages; it only installs packages that are missing. The script can also download necessary resources for NLTK and spaCy. This includes tokenizers, taggers, and the en_core_web_lg spaCy model. Existing resources are not overwritten.\r\n",
    "\n",
    "By default, it will also run the Additional Analysis. If you do not want the Additional Analysis to run, set RUN_ADDITIONAL_ANALYSIS = False. \r",
    "t\n",
    "All figures, tables, and results are saved automatically in the corresponding folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0fb740-4d1c-401e-bda0-7e71e42213ca",
   "metadata": {},
   "source": [
    "##  Installation of required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3e6f260-fcf6-44de-9e45-9371d5014c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package already installed: gensim\n",
      "Package already installed: joblib\n",
      "Package already installed: matplotlib\n",
      "Package already installed: nbconvert\n",
      "Package already installed: nltk\n",
      "Package already installed: numpy\n",
      "Package already installed: pandas\n",
      "Package already installed: pycountry\n",
      "Package already installed: rapidfuzz\n",
      "Package already installed: scipy\n",
      "Package already installed: seaborn\n",
      "Package already installed: spacy\n",
      "Installing package: tableone\n",
      "Package already installed: tabulate\n",
      "Package already installed: tqdm\n",
      "NLTK resource already exists: punkt\n",
      "NLTK resource already exists: averaged_perceptron_tagger\n",
      "spaCy model already exists: en_core_web_lg\n"
     ]
    }
   ],
   "source": [
    "# If set to true it installs the following packages (The function will only install packages that are not installed yet):\n",
    "\n",
    "InstallPackages = True \n",
    "\n",
    "if InstallPackages:\n",
    "    import sys\n",
    "    import subprocess\n",
    "    import importlib\n",
    "\n",
    "    packages = [\n",
    "         \"gensim\",\n",
    "        \"joblib\",\n",
    "        \"matplotlib\",\n",
    "        \"nbconvert\",\n",
    "        \"nltk\",\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"pycountry\",\n",
    "        \"rapidfuzz\",\n",
    "        \"scipy\",\n",
    "        \"seaborn\",\n",
    "        \"spacy\",\n",
    "        \"tableone\",\n",
    "        \"tabulate\",\n",
    "        \"tqdm\"\n",
    "        \n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        if importlib.util.find_spec(package) is None:\n",
    "            print(f\"Installing package: {package}\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        else:\n",
    "            print(f\"Package already installed: {package}\")\n",
    "\n",
    "# Set to True to download resources; it will only install resources that are missing\n",
    "DownloadAdditions = True  \n",
    "\n",
    "if DownloadAdditions:\n",
    "    import nltk\n",
    "    import spacy\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    # --- NLTK resources ---\n",
    "    nltk_packages = [\"punkt\", \"averaged_perceptron_tagger\"]\n",
    "    for pkg in nltk_packages:\n",
    "        try:\n",
    "            nltk.data.find(f\"tokenizers/{pkg}\" if pkg == \"punkt\" else f\"taggers/{pkg}\")\n",
    "            print(f\"NLTK resource already exists: {pkg}\")\n",
    "        except LookupError:\n",
    "            print(f\"Downloading NLTK resource: {pkg}\")\n",
    "            nltk.download(pkg)\n",
    "\n",
    "    # --- spaCy model ---\n",
    "    spacy_model = \"en_core_web_lg\"\n",
    "    try:\n",
    "        spacy.load(spacy_model)\n",
    "        print(f\"spaCy model already exists: {spacy_model}\")\n",
    "    except OSError:\n",
    "        print(f\"Downloading spaCy model: {spacy_model}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", spacy_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce23377-f5c6-48e3-abd9-eec2995721f8",
   "metadata": {},
   "source": [
    "## Run Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56dc991c-abb3-4aa4-80f9-6cdbb9fe004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd05c269-3bfa-48c4-8969-377ee22fe0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_notebook(notebook_path, timeout=20000):\n",
    "    \"\"\"\n",
    "    Executes the Jupyter notebooks automatically.\n",
    "\n",
    "    The notebook is loaded and run cell-by-cell.\n",
    "    \"\"\"\n",
    "    notebook_path = Path(notebook_path)\n",
    "    if not notebook_path.exists():\n",
    "        raise FileNotFoundError(f\"Notebook {notebook_path} not found.\")\n",
    "\n",
    "    print(f\"Running notebook: {notebook_path.name} ...\")\n",
    "    with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    ep = ExecutePreprocessor(timeout=timeout, kernel_name=\"python3\")\n",
    "    ep.preprocess(nb, {'metadata': {'path': notebook_path.parent}})\n",
    "\n",
    "    print(f\"Finished notebook: {notebook_path.name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a388c295-0b23-4d39-9607-b86f9f64bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook: 0_data_creation.ipynb ...\n",
      "Finished notebook: 0_data_creation.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_notebook(\"notebooks/0_data_creation.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ff22f9d-bfd2-4b62-acc4-b15ee3424c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook: 1_model_training_centroids_scoring.ipynb ...\n",
      "Finished notebook: 1_model_training_centroids_scoring.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_notebook(\"notebooks/1_model_training_centroids_scoring.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe8a672a-0277-4f84-82fc-cfcc5dd9d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook: 2_figures.ipynb ...\n",
      "Finished notebook: 2_figures.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_notebook(\"notebooks/2_figures.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae4283ac-2f9f-44a3-9892-a4a7903b42b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook: 3_tables.ipynb ...\n",
      "Finished notebook: 3_tables.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_notebook(\"notebooks/3_tables.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c57273-07a6-405b-871c-4437f5e25516",
   "metadata": {},
   "source": [
    "## Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "088e3348-0b37-41e1-b255-c3c68ca87d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Additional Analysis Notebooks...\n",
      "Running notebook: 0_data_creation_changed_weighted_freq.ipynb ...\n",
      "Finished notebook: 0_data_creation_changed_weighted_freq.ipynb\n",
      "\n",
      "Running notebook: 1_model_training_centroids_scoring_changed_weighted_freq.ipynb ...\n",
      "Finished notebook: 1_model_training_centroids_scoring_changed_weighted_freq.ipynb\n",
      "\n",
      "Running notebook: 0_data_creation_indiv_stopwords.ipynb ...\n",
      "Finished notebook: 0_data_creation_indiv_stopwords.ipynb\n",
      "\n",
      "Running notebook: 1_model_training_centroids_scoring_indiv_stopwords.ipynb ...\n",
      "Finished notebook: 1_model_training_centroids_scoring_indiv_stopwords.ipynb\n",
      "\n",
      "Running notebook: 2_figure_comparison_emotionality_score.ipynb ...\n",
      "Finished notebook: 2_figure_comparison_emotionality_score.ipynb\n",
      "\n",
      "All Notebooks for Additional analysis executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# === Optional: Run Additional Analysis ===\n",
    "# If you want to run also the additional analysis, then set the function here to TRUE\n",
    "RUN_ADDITIONAL_ANALYSIS =True  # Set to True to execute additional analysis notebooks\n",
    "\n",
    "if RUN_ADDITIONAL_ANALYSIS:\n",
    "    \"\"\"\n",
    "    Executes the additional analysis notebooks automatically.\n",
    "\n",
    "    Each notebook is loaded and run cell-by-cell.\n",
    "    \"\"\"\n",
    "    additional_notebooks = [\n",
    "        # Different Calculation Weighted Frequencies\n",
    "        \"notebooks/Additional Analysis/Different Calculation Weighted Frequencies/0_data_creation_changed_weighted_freq.ipynb\",\n",
    "        \"notebooks/Additional Analysis/Different Calculation Weighted Frequencies/1_model_training_centroids_scoring_changed_weighted_freq.ipynb\",\n",
    "\n",
    "        # Individual Stopwords\n",
    "        \"notebooks/Additional Analysis/Individual Stopwords/0_data_creation_indiv_stopwords.ipynb\",\n",
    "        \"notebooks/Additional Analysis/Individual Stopwords/1_model_training_centroids_scoring_indiv_stopwords.ipynb\",\n",
    "\n",
    "        # Figure Comparison Emotionality Score for the different calculations\n",
    "        \"notebooks/Additional Analysis/2_figure_comparison_emotionality_score.ipynb\",\n",
    "    ]\n",
    "\n",
    "    print(\"Running Additional Analysis Notebooks...\")\n",
    "    for nb in additional_notebooks:\n",
    "        run_notebook(nb)\n",
    "\n",
    "    print(\"All Notebooks for Additional analysis executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace00de6-2e06-4e9d-8e7c-25ca55f7c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
