{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db1c9d3-7c78-4a15-a472-471726d133d9",
   "metadata": {},
   "source": [
    "# Development of Emotion and Reasoning in the General Speeches of the United Nations: A text-based machine learning approach\n",
    "## Script 3: Tables\n",
    "### Author: Sarah Franzen\n",
    "\n",
    "### Instructions BEFORE running this script:\n",
    "- Ensure you ran Script 0-2 before completely to create proper folder structure and to get the required data\n",
    "\n",
    "### Description: \n",
    "#### This file creates the following figures and tables\n",
    "\n",
    "Tables\n",
    "- Summary Statistics of the given variables\n",
    "- Summary Statistics Emotionality Scoring - per Decade\n",
    "- Summary Statistics Emotionality Scoring - XXXX\n",
    "- T-Test for suplementary data on Gender and Position of the Speaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dc1a494-66ea-49fa-88cc-07e288b32ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped due to missing score: 0\n"
     ]
    }
   ],
   "source": [
    "# == Import libraries for data processing and visualization ==\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "# === Set Working Directory ===\n",
    "# Prompt user to enter working directory path\n",
    "#wd = input(\"Please enter your working directory path (e.g., C:\\\\Users\\\\sarah\\\\OneDrive\\\\Dokumente\\\\Masterarbeit): \").strip()\n",
    "\n",
    "# Change to the entered working directory\n",
    "#try:\n",
    "   # os.chdir(wd)\n",
    "    #print(f\"Working directory set to: {os.getcwd()}\")\n",
    "#except FileNotFoundError:\n",
    "   # print(\"ERROR: The directory you entered does not exist. Please restart and enter a valid path.\")\n",
    "    #exit(1)\n",
    "\n",
    "# Set your working directory (adjust this as needed)\n",
    "wd = r\"C:\\Users\\sarah\\OneDrive\\Dokumente\\Masterarbeit\"\n",
    "\n",
    "# === Define Folder Paths ===\n",
    "data_c = os.path.join(wd, 'data')\n",
    "data_results = os.path.join(data_c, 'results')\n",
    "data_temp = os.path.join(data_c, 'temp')\n",
    "data_freq = os.path.join(data_c, 'freq')\n",
    "tables_dir = os.path.join(wd, 'tables')\n",
    "\n",
    "# === Load data ===\n",
    "\n",
    "os.chdir(tables_dir)\n",
    "un_corpus_scored = pd.read_csv(\n",
    "    os.path.join(data_results, \"un_corpus_scored.csv\"),\n",
    "    sep=';', \n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "# Ensure no Missings in the emotionality scoring\n",
    "rows_before = len(un_corpus_scored)\n",
    "un_corpus_scored = un_corpus_scored[un_corpus_scored['score'].notna()]\n",
    "print(f\"Rows dropped due to missing score: {rows_before - len(un_corpus_scored)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1ddb6-346c-47f7-ac7f-052df13ec12c",
   "metadata": {},
   "source": [
    "## Summary Statistics of the given variables\n",
    "Create Table and export as tex-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42a618ed-6ccb-4996-b5e9-0fd24110a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seperate dummies on the position variable to get a nice summary table\n",
    "\n",
    "position_nonmissing = un_corpus_scored['position'].notna()\n",
    "\n",
    "position_dummies = pd.get_dummies(un_corpus_scored.loc[position_nonmissing, 'position'])\n",
    "\n",
    "position_dummies = position_dummies.astype(int)\n",
    "\n",
    "position_dummies = position_dummies.reindex(un_corpus_scored.index)\n",
    "\n",
    "position_dummies.loc[~position_nonmissing, :] = pd.NA\n",
    "\n",
    "position_dummies = position_dummies.astype(\"Int64\")\n",
    "\n",
    "un_corpus_scored = pd.concat([un_corpus_scored, position_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cfc08f8-318c-4006-9238-595f4bd31bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Variable   Obs      Mean        SD  Min   Max\n",
      "                                                         Year 10952  1993.296    20.186 1946  2024\n",
      "                                              Number of Words 10952   2913.75  1502.019  423 22003\n",
      "                       English as Official Language (Yes = 1) 10952     0.239     0.426    0     1\n",
      "                  Permanent Member Security Council (Yes = 1) 10952     0.035     0.185    0     1\n",
      "                                          Gender (Female = 1)  4704     0.039     0.193    0     1\n",
      "                                                     Position            <NA>      <NA> <NA>  <NA>\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;(Deputy) Minister for Foreign Affairs  6273     0.381     0.486    0     1\n",
      "              &nbsp;&nbsp;&nbsp;&nbsp;(Deputy) Prime Minister  6273     0.198     0.398    0     1\n",
      "                    &nbsp;&nbsp;&nbsp;&nbsp;(Vice-) President  6273     0.328      0.47    0     1\n",
      "            &nbsp;&nbsp;&nbsp;&nbsp;Diplomatic Representative  6273     0.054     0.226    0     1\n",
      "                               &nbsp;&nbsp;&nbsp;&nbsp;Others  6273      0.04     0.195    0     1\n"
     ]
    }
   ],
   "source": [
    "all_numeric_vars = ['year', 'speech_length_words', 'english_official_language',\n",
    "                    'security_council_permanent', 'gender_dummy'] + list(position_dummies.columns)\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Variable\": all_numeric_vars,\n",
    "    \"Obs\": un_corpus_scored[all_numeric_vars].count().astype(int),\n",
    "    \"Mean\": un_corpus_scored[all_numeric_vars].mean().round(3),\n",
    "    \"SD\": un_corpus_scored[all_numeric_vars].std().round(3),\n",
    "    \"Min\": un_corpus_scored[all_numeric_vars].min(),\n",
    "    \"Max\": un_corpus_scored[all_numeric_vars].max()\n",
    "})\n",
    "\n",
    "position_header = pd.DataFrame({\n",
    "    \"Variable\": [\"Position\"],\n",
    "    \"Obs\": [\"\"],\n",
    "    \"Mean\": [\"\"],\n",
    "    \"SD\": [\"\"],\n",
    "    \"Min\": [\"\"],\n",
    "    \"Max\": [\"\"]\n",
    "})\n",
    "\n",
    "insert_idx = 5\n",
    "summary_table = pd.concat([summary_table.iloc[:insert_idx],\n",
    "                           position_header,\n",
    "                           summary_table.iloc[insert_idx:]]).reset_index(drop=True)\n",
    "\n",
    "var_labels = {\n",
    "    \"year\": \"Year\",\n",
    "    \"speech_length_words\": \"Number of Words\",\n",
    "    \"english_official_language\": \"English as Official Language (Yes = 1)\",\n",
    "    \"security_council_permanent\": \"Permanent Member Security Council (Yes = 1)\",\n",
    "    \"gender_dummy\": \"Gender (Female = 1)\",\n",
    "    \"(Deputy) Minister for Foreign Affairs\": \"&nbsp;&nbsp;&nbsp;&nbsp;(Deputy) Minister for Foreign Affairs\",\n",
    "    \"(Deputy) Prime Minister\": \"&nbsp;&nbsp;&nbsp;&nbsp;(Deputy) Prime Minister\",\n",
    "    \"(Vice-) President\": \"&nbsp;&nbsp;&nbsp;&nbsp;(Vice-) President\",\n",
    "    \"Diplomatic Representative\": \"&nbsp;&nbsp;&nbsp;&nbsp;Diplomatic Representative\",\n",
    "    \"Others\": \"&nbsp;&nbsp;&nbsp;&nbsp;Others\"\n",
    "}\n",
    "summary_table['Variable'] = summary_table['Variable'].replace(var_labels)\n",
    "\n",
    "numeric_cols = ['Mean','SD','Min','Max']\n",
    "summary_table[numeric_cols] = summary_table[numeric_cols].replace(\"\", pd.NA)\n",
    "\n",
    "summary_table[['Min', 'Max']] = summary_table[['Min', 'Max']].astype('Int64')\n",
    "\n",
    "styled_table = summary_table.style \\\n",
    "    .hide(axis=\"index\") \\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('border-bottom', '3px solid black'), \n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold'),\n",
    "            ('text-align', 'center'),\n",
    "            ('background-color', 'white')\n",
    "        ]},\n",
    "        {'selector': 'th.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col1', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col2', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col3', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col4', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col5', 'props': [('min-width', '80px')]}\n",
    "    ]) \\\n",
    "    .set_properties(**{'text-align': 'center'}, subset=['Obs','Mean','SD','Min','Max']) \\\n",
    "    .format({\"Mean\": \"{:.3f}\", \"SD\": \"{:.3f}\"})\n",
    "\n",
    "# --- EXPORT HTML ---\n",
    "styled_table.to_html(\"Summary_Statistics_Table.html\")\n",
    "\n",
    "# --- EXPORT LaTeX ---\n",
    "latex_ready = summary_table.copy()\n",
    "latex_ready[\"Variable\"] = latex_ready[\"Variable\"].apply(\n",
    "    lambda x: re.sub(r\"&nbsp;+\", r\"\\\\hspace*{1em}\", str(x)) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "latex_table = latex_ready.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lrrrrr\",\n",
    "    caption=\"Summary Statistics\",\n",
    "    label=\"tab:summary_stats\",\n",
    "    header=[\"Variable\", \"Obs\", \"Mean\", \"SD\", \"Min\", \"Max\"],\n",
    "    bold_rows=False,\n",
    "    escape=False  \n",
    ")\n",
    "\n",
    "\n",
    "latex_table = latex_table.replace(\n",
    "    \"\\\\toprule\",\n",
    "    \"\\\\hline\\\\hline\"\n",
    ").replace(\n",
    "    \"\\\\midrule\",\n",
    "    \"\\\\hline\"\n",
    ").replace(\n",
    "    \"\\\\bottomrule\",\n",
    "    \"\\\\hline\\\\hline\"\n",
    ")\n",
    "\n",
    "# Save LaTeX file\n",
    "with open(\"Summary_Variables.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "\n",
    "\n",
    "print(summary_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def95526-bd21-4ce4-a230-9fff5cb0936e",
   "metadata": {},
   "source": [
    "### Summary Statistics Emotionality Scoring - Subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "138027d0-2b39-4621-856c-07874268c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable  Obs (Non-Missing)  Obs (Missing)  Mean (Non-Missing)  Mean (Missing)  t-test  p-value\n",
      "  Gender               4704           6248               0.820           0.800   5.136      0.0\n",
      "Position               6273           4679               0.793           0.829  -9.420      0.0\n"
     ]
    }
   ],
   "source": [
    "test_vars = ['gender_dummy', 'position']\n",
    "table_labels = {'gender_dummy': 'Gender', 'position': 'Position'}\n",
    "\n",
    "summary_list = []\n",
    "\n",
    "for var in test_vars:\n",
    "    scores = un_corpus_scored['score']\n",
    "\n",
    "    # Groups\n",
    "    group_non_missing = scores[un_corpus_scored[var].notna()]\n",
    "    group_missing = scores[un_corpus_scored[var].isna()]\n",
    "\n",
    "    # Means\n",
    "    mean_non_missing = round(group_non_missing.mean(), 3)\n",
    "    mean_missing = round(group_missing.mean(), 3)\n",
    "\n",
    "    # t-test\n",
    "    t_stat, p_val = stats.ttest_ind(group_non_missing, group_missing, nan_policy='omit')\n",
    "    t_stat = round(t_stat, 3)\n",
    "    p_val = round(p_val, 3)  \n",
    "\n",
    "    summary_list.append({\n",
    "        'Variable': table_labels[var],\n",
    "        'Obs (Non-Missing)': len(group_non_missing),\n",
    "        'Obs (Missing)': len(group_missing),\n",
    "        'Mean (Non-Missing)': mean_non_missing,\n",
    "        'Mean (Missing)': mean_missing,\n",
    "        't-test': t_stat,\n",
    "        'p-value': p_val\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(summary_list)\n",
    "\n",
    "# --- Styling ---\n",
    "styled_table = (\n",
    "    summary_df.style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('border-bottom', '3px solid black'), \n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold'),\n",
    "            ('text-align', 'center'),\n",
    "            ('background-color', 'white')\n",
    "        ]},\n",
    "        {'selector': 'th.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]},\n",
    "    ])\n",
    "    .set_properties(**{'text-align': 'center'})\n",
    "    .format({\n",
    "        \"Obs (Non-Missing)\": \"{:.0f}\",\n",
    "        \"Obs (Missing)\": \"{:.0f}\",\n",
    "        \"Mean (Non-Missing)\": \"{:.3f}\",\n",
    "        \"Mean (Missing)\": \"{:.3f}\",\n",
    "        \"t-test\": \"{:.3f}\",\n",
    "        \"p-value\": \"{:.3f}\"\n",
    "    }, na_rep=\"-\")\n",
    ")\n",
    "\n",
    "# --- Export HTML ---\n",
    "styled_table.to_html(\"TTest_Scoring_Gender_Position.html\")\n",
    "\n",
    "# --- Export LaTeX ---\n",
    "latex_ready = summary_df.copy()\n",
    "\n",
    "latex_table = latex_ready.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lrrrrrr\",\n",
    "    caption=\"Emotionality Scoring of the Subsamples with T-Tests\",\n",
    "    label=\"tab:summary_stats_ttest\",\n",
    "    header=[\"Variable\", \"Obs (Non-Missing)\", \"Obs (Missing)\", \n",
    "            \"Mean (Non-Missing)\", \"Mean (Missing)\", \"t-test\", \"p-value\"],\n",
    "    bold_rows=False,\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "# Replace top/mid/bottom rules for nicer formatting\n",
    "latex_table = (\n",
    "    latex_table.replace(\"\\\\toprule\", \"\\\\hline\\\\hline\")\n",
    "               .replace(\"\\\\midrule\", \"\\\\hline\")\n",
    "               .replace(\"\\\\bottomrule\", \"\\\\hline\\\\hline\")\n",
    ")\n",
    "\n",
    "with open(\"TTest_Scoring_Gender_Position.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "# Print summary table in console\n",
    "print(summary_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dd4bc-81b6-4bd5-b297-b8ac9b729f1c",
   "metadata": {},
   "source": [
    "### Summary Statistics Emotionality Scoring - per Decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012f1552-b6f4-4a14-98b0-b5ecd7c52345",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_start = (np.floor((un_corpus_scored['year'] - 1946) / 10) * 10 + 1946).astype(int)\n",
    "decade_end = decade_start + 9\n",
    "decade_end = decade_end.where(decade_end < 2024, 2024)\n",
    "\n",
    "un_corpus_scored['Decade'] = decade_start.astype(str) + \"â€“\" + decade_end.astype(str)\n",
    "\n",
    "decade_summary = (\n",
    "    un_corpus_scored.groupby('Decade')['score']\n",
    "    .agg(Obs='count', Mean='mean', SD='std', Min='min', Max='max')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "numeric_cols = ['Mean', 'SD', 'Min', 'Max']\n",
    "decade_summary[numeric_cols] = decade_summary[numeric_cols].round(3)\n",
    "\n",
    "styled_decade_table = (\n",
    "    decade_summary.style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('border-bottom', '3px solid black'),\n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold'),\n",
    "            ('text-align', 'center'),\n",
    "            ('background-color', 'white')\n",
    "        ]},\n",
    "        {'selector': 'th.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col1', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col2', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col3', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col4', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col5', 'props': [('min-width', '80px')]}\n",
    "    ])\n",
    "    .set_properties(**{'text-align': 'center'}, subset=['Obs', 'Mean', 'SD', 'Min', 'Max'])\n",
    "    .format({\n",
    "        'Obs': '{:.0f}',\n",
    "        'Mean': '{:.3f}',\n",
    "        'SD': '{:.3f}',\n",
    "        'Min': '{:.3f}',\n",
    "        'Max': '{:.3f}'\n",
    "    }, na_rep='-')\n",
    ")\n",
    "\n",
    "# --- EXPORT HTML ---\n",
    "styled_decade_table.to_html(\"Scoring_per_Decade.html\")\n",
    "\n",
    "# --- EXPORT LaTeX ---\n",
    "latex_table = decade_summary.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lrrrrr\",\n",
    "    caption=\"Emotionality Scoring by Decade\",\n",
    "    label=\"tab:summary_decade\",\n",
    "    header=[\"Decade\", \"Obs\", \"Mean\", \"SD\", \"Min\", \"Max\"],\n",
    "    bold_rows=False,\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "latex_table = (\n",
    "    latex_table.replace(\"\\\\toprule\", \"\\\\hline\\\\hline\")\n",
    "               .replace(\"\\\\midrule\", \"\\\\hline\")\n",
    "               .replace(\"\\\\bottomrule\", \"\\\\hline\\\\hline\")\n",
    ")\n",
    "\n",
    "with open(\"Scoring_per_Decade.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c167fb-9953-42bf-ab2b-813676a3dd4e",
   "metadata": {},
   "source": [
    "### Summary Statistics Emotionaly Scoring for categorial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28041f6-3754-461f-8b1a-149a30ca8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_vars = ['english_official_language', 'security_council_permanent', 'gender_dummy'] + list(position_dummies.columns)\n",
    "\n",
    "var_labels = {\n",
    "    'english_official_language': 'English as Official Language',\n",
    "    'security_council_permanent': 'Permanent Member of the Security Council',\n",
    "    'gender_dummy': 'Gender',\n",
    "}\n",
    "\n",
    "value_labels = {\n",
    "    'english_official_language': {1: 'Yes (=1)', 0: 'No (=0)'},\n",
    "    'security_council_permanent': {1: 'Yes (=1)', 0: 'No (=0)'},\n",
    "    'gender_dummy': {1: 'Female (=1)', 0: 'Male (=0)'}\n",
    "}\n",
    "\n",
    "summary_list = []\n",
    "position_header_inserted = False\n",
    "\n",
    "for var in group_vars:\n",
    "    # Insert \"Position\" header row once before position dummies\n",
    "    if var not in value_labels and not position_header_inserted:\n",
    "        position_header = pd.DataFrame({\n",
    "            'Variable': ['Position'],\n",
    "            'Obs': [\"\"],\n",
    "            'Mean': [\"\"],\n",
    "            'SD': [\"\"],\n",
    "            'Min': [\"\"],\n",
    "            'Max': [\"\"]\n",
    "        })\n",
    "        summary_list.append(position_header)\n",
    "        position_header_inserted = True\n",
    "    \n",
    "   \n",
    "    if var not in value_labels:\n",
    "        subset = un_corpus_scored[un_corpus_scored[var] == 1]\n",
    "        summary_list.append(pd.DataFrame({\n",
    "            'Variable': [f\"&nbsp;&nbsp;&nbsp;&nbsp;{var_labels.get(var, var)}\"],\n",
    "            'Obs': [subset['score'].count()],\n",
    "            'Mean': [subset['score'].mean()],\n",
    "            'SD': [subset['score'].std()],\n",
    "            'Min': [subset['score'].min()],\n",
    "            'Max': [subset['score'].max()]\n",
    "        }))\n",
    "    \n",
    "   \n",
    "    if var in value_labels:\n",
    "        # Variable header\n",
    "        summary_list.append(pd.DataFrame({\n",
    "            'Variable': [var_labels[var]],\n",
    "            'Obs': [\"\"],\n",
    "            'Mean': [\"\"],\n",
    "            'SD': [\"\"],\n",
    "            'Min': [\"\"],\n",
    "            'Max': [\"\"]\n",
    "        }))\n",
    "        for val in sorted(un_corpus_scored[var].dropna().unique()):\n",
    "            subset = un_corpus_scored[un_corpus_scored[var] == val]\n",
    "            summary_list.append(pd.DataFrame({\n",
    "                'Variable': [f\"&nbsp;&nbsp;&nbsp;&nbsp;{value_labels[var][val]}\"],\n",
    "                'Obs': [subset['score'].count()],\n",
    "                'Mean': [subset['score'].mean()],\n",
    "                'SD': [subset['score'].std()],\n",
    "                'Min': [subset['score'].min()],\n",
    "                'Max': [subset['score'].max()]\n",
    "            }))\n",
    "\n",
    "\n",
    "score_summary_table = pd.concat(summary_list, ignore_index=True)\n",
    "\n",
    "\n",
    "numeric_cols = ['Mean', 'SD', 'Min', 'Max']\n",
    "score_summary_table[numeric_cols] = score_summary_table[numeric_cols].round(3)\n",
    "score_summary_table[numeric_cols] = score_summary_table[numeric_cols].replace(\"\", pd.NA)\n",
    "\n",
    "styled_score_table = (\n",
    "    score_summary_table.style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('border-bottom', '3px solid black'),\n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold'),\n",
    "            ('text-align', 'center'),\n",
    "            ('background-color', 'white')\n",
    "        ]},\n",
    "        {'selector': 'th.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col1', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col2', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col3', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col4', 'props': [('min-width', '80px')]},\n",
    "        {'selector': 'td.col5', 'props': [('min-width', '80px')]}\n",
    "    ])\n",
    "    .set_properties(**{'text-align': 'center'}, subset=['Obs','Mean','SD','Min','Max'])\n",
    "    .format({col: \"{:.3f}\" for col in numeric_cols})\n",
    ")\n",
    "\n",
    "# --- EXPORT HTML ---\n",
    "styled_score_table.to_html(\"Scoring_categorial_variables.html\")\n",
    "\n",
    "# --- EXPORT LaTeX ---\n",
    "latex_table = score_summary_table.copy()\n",
    "\n",
    "latex_table['Variable'] = latex_table['Variable'].apply(\n",
    "    lambda x: str(x).replace(\"&nbsp;&nbsp;&nbsp;&nbsp;\", \"\\\\hspace*{1em}\") if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "latex_str = latex_table.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lrrrrr\",\n",
    "    caption=\"Emotionality Scoring for the categorial variables\",\n",
    "    label=\"tab:conditional_vars\",\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "\n",
    "latex_str = latex_str.replace(\"\\\\toprule\", \"\\\\hline\\\\hline\") \\\n",
    "                     .replace(\"\\\\midrule\", \"\\\\hline\") \\\n",
    "                     .replace(\"\\\\bottomrule\", \"\\\\hline\\\\hline\")\n",
    "\n",
    "with open(\"Scoring_categorial_variable.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23ddeec9-d1d0-42c1-9085-43a76d9a8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Filter data from 1994 onward ---\n",
    "df_filtered = un_corpus_scored[un_corpus_scored['year'] >= 1994]\n",
    "\n",
    "# --- Only position dummies ---\n",
    "position_vars = list(position_dummies.columns)\n",
    "\n",
    "summary_list = []\n",
    "\n",
    "# Insert \"Position\" header once\n",
    "position_header = pd.DataFrame({\n",
    "    'Variable': ['Position'],\n",
    "    'Obs': [\"\"],\n",
    "    'Mean': [\"\"],\n",
    "    'SD': [\"\"],\n",
    "    'Min': [\"\"],\n",
    "    'Max': [\"\"]\n",
    "})\n",
    "summary_list.append(position_header)\n",
    "\n",
    "# Loop through positions\n",
    "for var in position_vars:\n",
    "    subset = df_filtered[df_filtered[var] == 1]\n",
    "    summary_list.append(pd.DataFrame({\n",
    "        'Variable': [f\"&nbsp;&nbsp;&nbsp;&nbsp;{var_labels.get(var, var)}\"],\n",
    "        'Obs': [subset['score'].count()],\n",
    "        'Mean': [subset['score'].mean()],\n",
    "        'SD': [subset['score'].std()],\n",
    "        'Min': [subset['score'].min()],\n",
    "        'Max': [subset['score'].max()]\n",
    "    }))\n",
    "\n",
    "# Concatenate\n",
    "score_summary_table = pd.concat(summary_list, ignore_index=True)\n",
    "\n",
    "# Round numeric columns\n",
    "numeric_cols = ['Mean', 'SD', 'Min', 'Max']\n",
    "score_summary_table[numeric_cols] = score_summary_table[numeric_cols].round(3)\n",
    "score_summary_table[numeric_cols] = score_summary_table[numeric_cols].replace(\"\", pd.NA)\n",
    "\n",
    "# --- Styling ---\n",
    "styled_score_table = (\n",
    "    score_summary_table.style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('border-bottom', '3px solid black'),\n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold'),\n",
    "            ('text-align', 'center'),\n",
    "            ('background-color', 'white')\n",
    "        ]},\n",
    "        {'selector': 'th.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "    ])\n",
    "    .set_properties(**{'text-align': 'center'}, subset=['Obs','Mean','SD','Min','Max'])\n",
    "    .format({col: \"{:.3f}\" for col in numeric_cols})\n",
    ")\n",
    "\n",
    "# --- Export HTML ---\n",
    "styled_score_table.to_html(\"Scoring_positions_from1994.html\")\n",
    "\n",
    "# --- Export LaTeX ---\n",
    "latex_table = score_summary_table.copy()\n",
    "latex_table['Variable'] = latex_table['Variable'].apply(\n",
    "    lambda x: str(x).replace(\"&nbsp;&nbsp;&nbsp;&nbsp;\", \"\\\\hspace*{1em}\") if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "latex_str = latex_table.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lrrrrr\",\n",
    "    caption=\"Emotionality Scoring for the positions (1994 and later)\",\n",
    "    label=\"tab:positions_1994\",\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "latex_str = latex_str.replace(\"\\\\toprule\", \"\\\\hline\\\\hline\") \\\n",
    "                     .replace(\"\\\\midrule\", \"\\\\hline\") \\\n",
    "                     .replace(\"\\\\bottomrule\", \"\\\\hline\\\\hline\")\n",
    "\n",
    "with open(\"Scoring_positions_from1994.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "934aa3ae-f827-4633-bc71-7caba93ae04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter data from 1994 onward ---\n",
    "df_filtered = un_corpus_scored[un_corpus_scored['year'] >= 1994]\n",
    "\n",
    "# --- Only position dummies ---\n",
    "position_vars = list(position_dummies.columns)\n",
    "\n",
    "summary_list = []\n",
    "\n",
    "# Insert \"Position\" header once\n",
    "position_header = pd.DataFrame({\n",
    "    'Variable': ['Position'],\n",
    "    'Obs': [\"\"],\n",
    "    'Mean': [\"\"],\n",
    "    'SD': [\"\"],\n",
    "    'Min': [\"\"],\n",
    "    'Max': [\"\"]\n",
    "})\n",
    "summary_list.append(position_header)\n",
    "\n",
    "# Loop through positions\n",
    "for var in position_vars:\n",
    "    subset = df_filtered[df_filtered[var] == 1]\n",
    "    summary_list.append(pd.DataFrame({\n",
    "        'Variable': [f\"&nbsp;&nbsp;&nbsp;&nbsp;{var_labels.get(var, var)}\"],\n",
    "        'Obs': [subset['score'].count()],\n",
    "        'Mean': [subset['score'].mean()],\n",
    "        'SD': [subset['score'].std()],\n",
    "        'Min': [subset['score'].min()],\n",
    "        'Max': [subset['score'].max()]\n",
    "    }))\n",
    "\n",
    "# Add overall row for 1994-2024\n",
    "overall_subset = df_filtered['score']\n",
    "overall_row = pd.DataFrame({\n",
    "    'Variable': ['Overall'],\n",
    "    'Obs': [overall_subset.count()],\n",
    "    'Mean': [overall_subset.mean()],\n",
    "    'SD': [overall_subset.std()],\n",
    "    'Min': [overall_subset.min()],\n",
    "    'Max': [overall_subset.max()]\n",
    "})\n",
    "summary_list.append(overall_row)\n",
    "\n",
    "# Concatenate\n",
    "score_summary_table = pd.concat(summary_list, ignore_index=True)\n",
    "\n",
    "# Round numeric columns\n",
    "numeric_cols = ['Mean', 'SD', 'Min', 'Max']\n",
    "score_summary_table[numeric_cols] = score_summary_table[numeric_cols].round(3)\n",
    "score_summary_table[numeric_cols] = score_summary_table[numeric_cols].replace(\"\", pd.NA)\n",
    "\n",
    "# --- Styling ---\n",
    "styled_score_table = (\n",
    "    score_summary_table.style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [\n",
    "            ('border-bottom', '3px solid black'),\n",
    "            ('color', 'black'),\n",
    "            ('font-weight', 'bold'),\n",
    "            ('text-align', 'center'),\n",
    "            ('background-color', 'white')\n",
    "        ]},\n",
    "        {'selector': 'th.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td.col0', 'props': [('text-align', 'left')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "    ])\n",
    "    .set_properties(**{'text-align': 'center'}, subset=['Obs','Mean','SD','Min','Max'])\n",
    "    .format({col: \"{:.3f}\" for col in numeric_cols})\n",
    ")\n",
    "\n",
    "# --- Export HTML ---\n",
    "styled_score_table.to_html(\"Scoring_positions_from1994.html\")\n",
    "\n",
    "# --- Export LaTeX ---\n",
    "latex_table = score_summary_table.copy()\n",
    "latex_table['Variable'] = latex_table['Variable'].apply(\n",
    "    lambda x: str(x).replace(\"&nbsp;&nbsp;&nbsp;&nbsp;\", \"\\\\hspace*{1em}\") if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "latex_str = latex_table.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lrrrrr\",\n",
    "    caption=\"Emotionality Scoring for the positions (1994 and later)\",\n",
    "    label=\"tab:positions_1994\",\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "latex_str = latex_str.replace(\"\\\\toprule\", \"\\\\hline\\\\hline\") \\\n",
    "                     .replace(\"\\\\midrule\", \"\\\\hline\") \\\n",
    "                     .replace(\"\\\\bottomrule\", \"\\\\hline\\\\hline\")\n",
    "\n",
    "with open(\"Scoring_positions_from1994.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3de83e3a-505f-4a1c-932f-55b06b394e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_dummy  0.0  1.0\n",
      "year                  \n",
      "1946           35    1\n",
      "1947           33    1\n",
      "1948           35    1\n",
      "1949           33    0\n",
      "1950           42    0\n",
      "1951           43    1\n",
      "1952           40    2\n",
      "1953           43    0\n",
      "1954           41    0\n",
      "1955           43    0\n",
      "1956           64    1\n",
      "1957           68    1\n",
      "1958           67    1\n",
      "1959           77    1\n",
      "1960           71    1\n",
      "1961           76    1\n",
      "1962           82    1\n",
      "1963           61    1\n",
      "1964           94    0\n",
      "1965           96    1\n",
      "1966          103    0\n",
      "1967          107    0\n",
      "1968          107    1\n",
      "1969          113    0\n",
      "1970           70    0\n",
      "1971          112    1\n",
      "1972          108    0\n",
      "1973            1    0\n",
      "1974          120    0\n",
      "1975          118    2\n",
      "1976          123    2\n",
      "1977            1    1\n",
      "1981          129    3\n",
      "1982            5    0\n",
      "1983            3    3\n",
      "1985          129    1\n",
      "1986          134    4\n",
      "1987            8    1\n",
      "1988           49    0\n",
      "1989            6    2\n",
      "1990            1    0\n",
      "1991            2    1\n",
      "1992          136    5\n",
      "1993          152    8\n",
      "1994          153    8\n",
      "1995          157    9\n",
      "1996            1    0\n",
      "1997            1    0\n",
      "1998            1    0\n",
      "2001            2    0\n",
      "2002            2    0\n",
      "2004          129    5\n",
      "2005            3    0\n",
      "2006          124   15\n",
      "2007            3    1\n",
      "2010            2    0\n",
      "2012            2    0\n",
      "2014            2    0\n",
      "2015          134   17\n",
      "2016          165   18\n",
      "2017          163   19\n",
      "2018          165   18\n",
      "2019          166   15\n",
      "2020          165    8\n"
     ]
    }
   ],
   "source": [
    "## Appendix\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "gender_per_year = (\n",
    "    un_corpus_scored\n",
    "    .groupby(['year', 'gender_dummy'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(gender_per_year)\n",
    "\n",
    "pd.reset_option(\"display.max_rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
