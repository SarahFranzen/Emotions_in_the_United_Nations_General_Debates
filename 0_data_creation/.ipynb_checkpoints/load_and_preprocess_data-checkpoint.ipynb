{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dcc954-1561-4ebe-983d-5c10d735e9b9",
   "metadata": {},
   "source": [
    "# Emotion and Reason in Political Language: Examining the UN General speeches\n",
    "### Sarah Franzen\n",
    "\n",
    "### Description: \n",
    "### - Extract documents from their original txt and store them as one csv\n",
    "### - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56fa9a21-650f-4d8e-8a21-3d9629655c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "# Define your temp folder path (adjust if needed)\n",
    "data_temp = r\"C:\\Users\\sarah\\OneDrive\\Dokumente\\Masterarbeit\\data\\temp\"\n",
    "\n",
    "wd = r\"C:\\Users\\sarah\\OneDrive\\Dokumente\\Masterarbeit\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93d247a0-5ff2-4062-add9-f3267ae1fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved 10761 speeches to 'C:\\Users\\sarah\\OneDrive\\Dokumente\\Master\\Thesis\\data\\un_corpus.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load data from txt-files into one csv-file\n",
    "\n",
    "# Define the base folder path\n",
    "base_folder = r\"C:\\Users\\sarah\\OneDrive\\Dokumente\\Masterarbeit\\data\\data_official_website\\UN General Debate Corpus\\UNGDC_1946-2023\\TXT\"\n",
    "\n",
    "# Create a list to hold the data\n",
    "data = []\n",
    "\n",
    "# Walk through all subfolders and process each .txt file\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt') and not file.startswith('._'):\n",
    "            filepath = os.path.join(root, file)\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "                # 1. Remove line breaks and carriage returns\n",
    "                content = content.replace('\\n', ' ').replace('\\r', ' ')\n",
    "\n",
    "                # 2. Collapse multiple spaces\n",
    "                content = ' '.join(content.split())\n",
    "\n",
    "                # 3. Fix punctuation spacing (e.g. \"word,another\" → \"word, another\")\n",
    "                content = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', content)\n",
    "\n",
    "                # 4. Remove hyphenation at line breaks (e.g. \"inter- national\" → \"international\")\n",
    "                content = re.sub(r'-\\s', '', content)\n",
    "\n",
    "                # 5. Remove stray backslashes\n",
    "                content = content.replace(\"\\\\\", \"\")\n",
    "\n",
    "                # 6. Escape double quotes for CSV safety\n",
    "                content = content.replace('\"', '\"\"')\n",
    "\n",
    "                # 7. Skip empty or nearly empty speeches\n",
    "                if len(content.strip().split()) == 0:\n",
    "                    continue\n",
    "\n",
    "                data.append({'filename': file, 'speech': content})\n",
    "\n",
    "# Create DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV with semicolon separator so Excel opens it correctly\n",
    "output_path = r\"C:\\Users\\sarah\\OneDrive\\Dokumente\\Masterarbeit\\data\\un_corpus_raw.csv\"\n",
    "df.to_csv(output_path, index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "print(f\"\\n✅ Saved {len(df)} speeches to '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6bd148-d5cf-4eb3-a66d-fc706e99c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'data' is your cleaned speeches list of lists: [[filename, speech], ...]\n",
    "data_id1 = data[:int(len(data)/4)]\n",
    "data_id2 = data[int(len(data)/4): int(2*len(data)/4)]\n",
    "data_id3 = data[int(2*len(data)/4): int(3*len(data)/4)]\n",
    "data_id4 = data[int(3*len(data)/4):]\n",
    "\n",
    "# Change directory to the temp folder\n",
    "os.chdir(data_temp)\n",
    "\n",
    "# Save each chunk with joblib\n",
    "joblib.dump(data_id1, 'rawspeeches_indexed1_n.pkl')\n",
    "joblib.dump(data_id2, 'rawspeeches_indexed2_n.pkl')\n",
    "joblib.dump(data_id3, 'rawspeeches_indexed3_n.pkl')\n",
    "joblib.dump(data_id4, 'rawspeeches_indexed4_n.pkl')\n",
    "\n",
    "print(f\"✅ Saved cleaned speeches chunks in '{data_temp}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
